{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTjpZEsuogEb+L0GAX9WSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalahmedgb/handsonML/blob/main/Chapter_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FwDpfCKRWWs"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib as mpl"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLbgwXAdRqa2"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0uGoaI_RTvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03beb6c0-d933-4fa7-8250-7736c70c7207"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\r\n",
        "\r\n",
        "X_train_full = X_train_full/255.\r\n",
        "X_test = X_test/255.\r\n",
        "\r\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\r\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42KZvyUYUcTX"
      },
      "source": [
        "pixel_means = X_train.mean(axis=0, keepdims=True)\r\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\r\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\r\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\r\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZG9gkN1SMDK"
      },
      "source": [
        "model = keras.models.Sequential()\r\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\r\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\r\n",
        "for layer in range(99):\r\n",
        "  model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\r\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3-Qyp-WT2m-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942a89d8-4c4a-488e-b5b8-78d707d80983"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 1,256,410\n",
            "Trainable params: 1,256,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmUOdAoaUB94"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\r\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\r\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO6dFI33USHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0160b900-fb6d-425e-be5d-7c6104cdad30"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=5,\r\n",
        "                    validation_data=(X_valid_scaled, y_valid))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 29s 15ms/step - loss: 2.0861 - accuracy: 0.2030 - val_loss: 2.6179 - val_accuracy: 0.1498\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 25s 15ms/step - loss: 1.4446 - accuracy: 0.4142 - val_loss: 2.9312 - val_accuracy: 0.2716\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 25s 15ms/step - loss: 0.9774 - accuracy: 0.5859 - val_loss: 2.1276 - val_accuracy: 0.2328\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 25s 14ms/step - loss: 1.1251 - accuracy: 0.5357 - val_loss: 2.3639 - val_accuracy: 0.3226\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 25s 15ms/step - loss: 0.8905 - accuracy: 0.6432 - val_loss: 1.9392 - val_accuracy: 0.3848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2EjkIJwVJmq"
      },
      "source": [
        "# Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX9ak8oIVJRR"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "              keras.layers.Flatten(input_shape=[28, 28]),\r\n",
        "              keras.layers.BatchNormalization(),\r\n",
        "              keras.layers.Dense(300, activation=\"relu\"),\r\n",
        "              keras.layers.BatchNormalization(),\r\n",
        "              keras.layers.Dense(100, activation=\"relu\"),\r\n",
        "              keras.layers.BatchNormalization(),\r\n",
        "              keras.layers.Dense(10, activation=\"softmax\")\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0iIREeKVpa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9ccf60-1d0e-4058-c295-19299a9bc368"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 300)               1200      \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmDeSFzHVrVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5513399e-33b2-4f2a-aa2b-086971db1e70"
      },
      "source": [
        "bn1 = model.layers[1]\r\n",
        "[(var.name, var.trainable) for var in bn1.variables] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization/gamma:0', True),\n",
              " ('batch_normalization/beta:0', True),\n",
              " ('batch_normalization/moving_mean:0', False),\n",
              " ('batch_normalization/moving_variance:0', False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFCJiWq8WASl"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\r\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\r\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tm_R_rQWW-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee10ece5-9396-498c-aaac-77b91d33ca42"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\r\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 10s 5ms/step - loss: 1.1978 - accuracy: 0.6090 - val_loss: 0.5573 - val_accuracy: 0.8104\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5995 - accuracy: 0.7932 - val_loss: 0.4745 - val_accuracy: 0.8398\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5193 - accuracy: 0.8187 - val_loss: 0.4425 - val_accuracy: 0.8496\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4781 - accuracy: 0.8321 - val_loss: 0.4196 - val_accuracy: 0.8554\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4559 - accuracy: 0.8389 - val_loss: 0.4045 - val_accuracy: 0.8602\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4452 - accuracy: 0.8428 - val_loss: 0.3926 - val_accuracy: 0.8626\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4246 - accuracy: 0.8511 - val_loss: 0.3829 - val_accuracy: 0.8664\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4157 - accuracy: 0.8517 - val_loss: 0.3759 - val_accuracy: 0.8690\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4032 - accuracy: 0.8566 - val_loss: 0.3703 - val_accuracy: 0.8670\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3905 - accuracy: 0.8609 - val_loss: 0.3646 - val_accuracy: 0.8696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odL2xZy9Wd2d"
      },
      "source": [
        "#Creating model with use_bias=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CayqfZXCXGKx"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\r\n",
        "    keras.layers.BatchNormalization(),\r\n",
        "    keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\", use_bias=False),\r\n",
        "    keras.layers.BatchNormalization(),\r\n",
        "    keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\", use_bias=False),\r\n",
        "    keras.layers.BatchNormalization(),\r\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5x_u3GHXZq0"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\r\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\r\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4ULPOgLXdzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7a0452-4b2a-4593-adb3-4ba01a010711"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\r\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 10s 5ms/step - loss: 1.3101 - accuracy: 0.5696 - val_loss: 0.5867 - val_accuracy: 0.8040\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.6449 - accuracy: 0.7792 - val_loss: 0.5023 - val_accuracy: 0.8316\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5698 - accuracy: 0.8052 - val_loss: 0.4625 - val_accuracy: 0.8418\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5230 - accuracy: 0.8179 - val_loss: 0.4385 - val_accuracy: 0.8498\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4918 - accuracy: 0.8300 - val_loss: 0.4205 - val_accuracy: 0.8554\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4736 - accuracy: 0.8344 - val_loss: 0.4090 - val_accuracy: 0.8600\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.4602 - accuracy: 0.8396 - val_loss: 0.3982 - val_accuracy: 0.8626\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4483 - accuracy: 0.8421 - val_loss: 0.3890 - val_accuracy: 0.8646\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4327 - accuracy: 0.8490 - val_loss: 0.3815 - val_accuracy: 0.8688\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4180 - accuracy: 0.8530 - val_loss: 0.3757 - val_accuracy: 0.8682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-r0W5A8-3Lo"
      },
      "source": [
        "# Reusing Pretrained Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gvm3cIk-5tY"
      },
      "source": [
        "def split_dataset(X, y):\r\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\r\n",
        "    y_A = y[~y_5_or_6]\r\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\r\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\r\n",
        "    return ((X[~y_5_or_6], y_A),\r\n",
        "            (X[y_5_or_6], y_B))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYrkdZOr-7Hy"
      },
      "source": [
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\r\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\r\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\r\n",
        "X_train_B = X_train_B[:200]\r\n",
        "y_train_B = y_train_B[:200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VCUl4-3_fET"
      },
      "source": [
        "#type(y_train_B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2tQt1bH_CXc",
        "outputId": "624a82e5-f669-49f8-b31f-bec34b311fa8"
      },
      "source": [
        "y_train_A[:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
              "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ3jANL-_L8Y",
        "outputId": "51ba0066-a701-42c1-8f7d-09fa8d2468dc"
      },
      "source": [
        "y_train_B[:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RNCqOop_R-N"
      },
      "source": [
        "tf.random.set_seed(42)\r\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rtdhPMI_1Go"
      },
      "source": [
        "model_A = keras.models.Sequential()\r\n",
        "model_A.add(keras.layers.Flatten(input_shape=[28,28]))\r\n",
        "\r\n",
        "for n_hidden in (300, 100, 50, 50, 50):\r\n",
        "  model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\r\n",
        "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fAWEilNAQaP",
        "outputId": "a94baf8f-d2cc-45b5-fa02-d1272a4bf359"
      },
      "source": [
        "model_A.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 8)                 408       \n",
            "=================================================================\n",
            "Total params: 276,158\n",
            "Trainable params: 276,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0odVvBHJAc8L"
      },
      "source": [
        "model_A.compile(loss=\"sparse_categorical_crossentropy\",\r\n",
        "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\r\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjFsuxhgAtG7",
        "outputId": "0c951f8e-64a3-49f9-a301-972e5bef6204"
      },
      "source": [
        "history = model_A.fit(X_train_A, y_train_A, epochs=20,\r\n",
        "                      validation_data=(X_valid_A, y_valid_A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1375/1375 [==============================] - 5s 4ms/step - loss: 0.9248 - accuracy: 0.6994 - val_loss: 0.3890 - val_accuracy: 0.8677\n",
            "Epoch 2/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.3651 - accuracy: 0.8748 - val_loss: 0.3289 - val_accuracy: 0.8824\n",
            "Epoch 3/20\n",
            "1375/1375 [==============================] - 4s 3ms/step - loss: 0.3182 - accuracy: 0.8897 - val_loss: 0.3013 - val_accuracy: 0.8991\n",
            "Epoch 4/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.3048 - accuracy: 0.8954 - val_loss: 0.2892 - val_accuracy: 0.9013\n",
            "Epoch 5/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2803 - accuracy: 0.9029 - val_loss: 0.2774 - val_accuracy: 0.9066\n",
            "Epoch 6/20\n",
            "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2700 - accuracy: 0.9080 - val_loss: 0.2733 - val_accuracy: 0.9071\n",
            "Epoch 7/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2625 - accuracy: 0.9091 - val_loss: 0.2720 - val_accuracy: 0.9091\n",
            "Epoch 8/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2608 - accuracy: 0.9117 - val_loss: 0.2589 - val_accuracy: 0.9141\n",
            "Epoch 9/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2557 - accuracy: 0.9108 - val_loss: 0.2562 - val_accuracy: 0.9143\n",
            "Epoch 10/20\n",
            "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2510 - accuracy: 0.9138 - val_loss: 0.2540 - val_accuracy: 0.9165\n",
            "Epoch 11/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2430 - accuracy: 0.9170 - val_loss: 0.2494 - val_accuracy: 0.9155\n",
            "Epoch 12/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2422 - accuracy: 0.9171 - val_loss: 0.2511 - val_accuracy: 0.9128\n",
            "Epoch 13/20\n",
            "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2359 - accuracy: 0.9181 - val_loss: 0.2446 - val_accuracy: 0.9163\n",
            "Epoch 14/20\n",
            "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2266 - accuracy: 0.9232 - val_loss: 0.2413 - val_accuracy: 0.9178\n",
            "Epoch 15/20\n",
            "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2224 - accuracy: 0.9242 - val_loss: 0.2446 - val_accuracy: 0.9193\n",
            "Epoch 16/20\n",
            "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2260 - accuracy: 0.9218 - val_loss: 0.2386 - val_accuracy: 0.9195\n",
            "Epoch 17/20\n",
            "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2191 - accuracy: 0.9250 - val_loss: 0.2405 - val_accuracy: 0.9175\n",
            "Epoch 18/20\n",
            "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2171 - accuracy: 0.9250 - val_loss: 0.2429 - val_accuracy: 0.9158\n",
            "Epoch 19/20\n",
            "1375/1375 [==============================] - 9s 7ms/step - loss: 0.2181 - accuracy: 0.9246 - val_loss: 0.2328 - val_accuracy: 0.9205\n",
            "Epoch 20/20\n",
            "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2112 - accuracy: 0.9272 - val_loss: 0.2332 - val_accuracy: 0.9208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEQsoPqlA2mW"
      },
      "source": [
        "model_A.save(\"my_model_A.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXznrnZ0BZmR"
      },
      "source": [
        "model_B = keras.models.Sequential()\r\n",
        "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\r\n",
        "for n_hidden in (300, 100, 50, 50, 50):\r\n",
        "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\r\n",
        "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzaTkR62CgPc"
      },
      "source": [
        "model_B.compile(loss=\"binary_crossentropy\",\r\n",
        "                optimizer=keras.optimizers.SGD(lr=1e-3),\r\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zI9BxikCiid",
        "outputId": "2033a24f-9690-4148-a36c-a6b01dfff24c"
      },
      "source": [
        "history = model_B.fit(X_train_B, y_train_B, epochs=20,\r\n",
        "                      validation_data=(X_valid_B, y_valid_B))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 1s 40ms/step - loss: 1.0360 - accuracy: 0.4975 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5883 - accuracy: 0.6971 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4380 - accuracy: 0.8854 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4021 - accuracy: 0.8712 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3361 - accuracy: 0.9348 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3113 - accuracy: 0.9233 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2817 - accuracy: 0.9299 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2632 - accuracy: 0.9379 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2373 - accuracy: 0.9481 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2229 - accuracy: 0.9657 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2155 - accuracy: 0.9590 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1834 - accuracy: 0.9738 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1671 - accuracy: 0.9828 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1527 - accuracy: 0.9915 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1595 - accuracy: 0.9904 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1473 - accuracy: 0.9937 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1412 - accuracy: 0.9944 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1242 - accuracy: 0.9931 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1224 - accuracy: 0.9931 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1096 - accuracy: 0.9912 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9EMgmlBCmlP",
        "outputId": "3423ddf5-a487-41ae-94d0-58687eb1f8ab"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 300)               235200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 300)               1200      \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 100)               30000     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 270,946\n",
            "Trainable params: 268,578\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tjt4Df5Co7A"
      },
      "source": [
        "model_A = keras.models.load_model(\"my_model_A.h5\")\r\n",
        "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\r\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz2qSZO11UWM",
        "outputId": "e8f8e1b0-d8ec-4450-a8d1-4ea125609550"
      },
      "source": [
        "model_A.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 8)                 408       \n",
            "=================================================================\n",
            "Total params: 276,158\n",
            "Trainable params: 276,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdQFL7-z1XDB",
        "outputId": "d570b2e4-9406-487c-f8b2-dd1d00bc143c"
      },
      "source": [
        "model_B_on_A.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 275,801\n",
            "Trainable params: 275,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ETH09px1IUQ"
      },
      "source": [
        "model_A_clone = keras.models.clone_model(model_A)\r\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVyaxDQs1tnr"
      },
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\r\n",
        "  layer.trainable = False\r\n",
        "\r\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\r\n",
        "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\r\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htUXvpvW3lA5",
        "outputId": "c8dfbf40-49e1-4752-a394-bdc1bc7c346a"
      },
      "source": [
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\r\n",
        "                           validation_data=(X_valid_B, y_valid_B))\r\n",
        "\r\n",
        "for layer in model_B_on_A.layers[:-1]:\r\n",
        "    layer.trainable = True\r\n",
        "\r\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\",\r\n",
        "                     optimizer=keras.optimizers.SGD(lr=1e-3),\r\n",
        "                     metrics=[\"accuracy\"])\r\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\r\n",
        "                           validation_data=(X_valid_B, y_valid_B))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "7/7 [==============================] - 1s 38ms/step - loss: 0.4701 - accuracy: 0.8218 - val_loss: 0.4436 - val_accuracy: 0.8174\n",
            "Epoch 2/4\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4001 - accuracy: 0.8649 - val_loss: 0.4145 - val_accuracy: 0.8306\n",
            "Epoch 3/4\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4021 - accuracy: 0.8326 - val_loss: 0.3880 - val_accuracy: 0.8458\n",
            "Epoch 4/4\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3533 - accuracy: 0.8887 - val_loss: 0.3650 - val_accuracy: 0.8529\n",
            "Epoch 1/16\n",
            "7/7 [==============================] - 1s 40ms/step - loss: 0.3287 - accuracy: 0.9006 - val_loss: 0.2487 - val_accuracy: 0.9523\n",
            "Epoch 2/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2008 - accuracy: 0.9877 - val_loss: 0.1968 - val_accuracy: 0.9797\n",
            "Epoch 3/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1694 - accuracy: 0.9931 - val_loss: 0.1655 - val_accuracy: 0.9899\n",
            "Epoch 4/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9919\n",
            "Epoch 5/16\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9929\n",
            "Epoch 6/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1139 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9919\n",
            "Epoch 7/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0997 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9919\n",
            "Epoch 8/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9919\n",
            "Epoch 9/16\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9919\n",
            "Epoch 10/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9919\n",
            "Epoch 11/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9919\n",
            "Epoch 12/16\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9919\n",
            "Epoch 13/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9919\n",
            "Epoch 14/16\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9919\n",
            "Epoch 15/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9919\n",
            "Epoch 16/16\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aglIbgU34FIi",
        "outputId": "08b798a2-a857-43c9-ce84-e77f1b8549e1"
      },
      "source": [
        "model_B.evaluate(X_test_B, y_test_B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14084088802337646, 0.9704999923706055]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "LMH9KIvs4InW",
        "outputId": "a2232186-611b-4d27-b2d8-e8951830a564"
      },
      "source": [
        "model_B_on_A.evaluate(X_test_B, y_test_B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf62c58a1dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_B_on_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_B_on_A' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifmH_XDb9yn4"
      },
      "source": [
        "# Learning Rate Scheduling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgwnRKni920z"
      },
      "source": [
        "# Power Scheduling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34EiZxBV948F"
      },
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOEAQTIf99_e"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "              keras.layers.Flatten(input_shape=[28, 28]),\r\n",
        "              keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\r\n",
        "              keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\r\n",
        "              keras.layers.Dense(10, activation=\"softmax\")\r\n",
        "])\r\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6DYMIu2-i-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b36a055-c7aa-4f87-9b3f-6c1b3e399ff0"
      },
      "source": [
        "n_epochs=25\r\n",
        "\r\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\r\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6037 - accuracy: 0.7890 - val_loss: 0.4025 - val_accuracy: 0.8598\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3882 - accuracy: 0.8625 - val_loss: 0.3720 - val_accuracy: 0.8718\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3530 - accuracy: 0.8766 - val_loss: 0.3705 - val_accuracy: 0.8698\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3318 - accuracy: 0.8814 - val_loss: 0.3479 - val_accuracy: 0.8784\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3208 - accuracy: 0.8854 - val_loss: 0.3420 - val_accuracy: 0.8770\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2956 - accuracy: 0.8943 - val_loss: 0.3404 - val_accuracy: 0.8826\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2909 - accuracy: 0.8972 - val_loss: 0.3348 - val_accuracy: 0.8836\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2747 - accuracy: 0.9026 - val_loss: 0.3381 - val_accuracy: 0.8788\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2755 - accuracy: 0.9013 - val_loss: 0.3295 - val_accuracy: 0.8842\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2626 - accuracy: 0.9076 - val_loss: 0.3273 - val_accuracy: 0.8836\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2548 - accuracy: 0.9114 - val_loss: 0.3270 - val_accuracy: 0.8858\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2497 - accuracy: 0.9126 - val_loss: 0.3377 - val_accuracy: 0.8802\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2442 - accuracy: 0.9143 - val_loss: 0.3253 - val_accuracy: 0.8878\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2406 - accuracy: 0.9137 - val_loss: 0.3281 - val_accuracy: 0.8852\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2392 - accuracy: 0.9154 - val_loss: 0.3234 - val_accuracy: 0.8846\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2342 - accuracy: 0.9174 - val_loss: 0.3210 - val_accuracy: 0.8856\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2257 - accuracy: 0.9219 - val_loss: 0.3244 - val_accuracy: 0.8902\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2265 - accuracy: 0.9199 - val_loss: 0.3199 - val_accuracy: 0.8890\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2259 - accuracy: 0.9210 - val_loss: 0.3223 - val_accuracy: 0.8886\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2242 - accuracy: 0.9224 - val_loss: 0.3203 - val_accuracy: 0.8876\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2213 - accuracy: 0.9241 - val_loss: 0.3203 - val_accuracy: 0.8886\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2184 - accuracy: 0.9234 - val_loss: 0.3188 - val_accuracy: 0.8890\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2144 - accuracy: 0.9247 - val_loss: 0.3203 - val_accuracy: 0.8886\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2078 - accuracy: 0.9284 - val_loss: 0.3214 - val_accuracy: 0.8872\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2121 - accuracy: 0.9272 - val_loss: 0.3210 - val_accuracy: 0.8902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEPuxu7H-77b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "7e1cb6cd-bf0b-483b-cc9c-ccbca63425d6"
      },
      "source": [
        "learning_rate = 0.01\r\n",
        "decay = 1e-4\r\n",
        "batch_size = 32\r\n",
        "n_steps_per_epoch = len(X_train) // batch_size\r\n",
        "epochs = np.arange(n_epochs)\r\n",
        "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\r\n",
        "\r\n",
        "plt.plot(epochs, lrs, \"o-\")\r\n",
        "plt.axis([0, n_epochs - 1, 0, 0.01])\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.ylabel(\"Learning Rate\")\r\n",
        "plt.title(\"Power Scheduling\", fontsize=14)\r\n",
        "plt.grid(True)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snZtgkhB_5tC"
      },
      "source": [
        "# Exponential Scheduling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz9ywpE1Achg"
      },
      "source": [
        "def exponential_decay_fn(epoch):\r\n",
        "  return 0.01 * 0.1**(epoch/20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfgWAzM1AjR3"
      },
      "source": [
        "def exponential_decay(lr0, s):\r\n",
        "  def exponential_decay_fn(epoch):\r\n",
        "    return lr0 * 0.1**(epoch / s)\r\n",
        "  return exponential_decay_fn\r\n",
        "\r\n",
        "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIA85MKYA8MB"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "                    keras.layers.Flatten(input_shape=[28, 28]),\r\n",
        "                    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\r\n",
        "                    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\r\n",
        "                    keras.layers.Dense(10, activation=\"softmax\")\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\r\n",
        "n_epochs = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw--bcaLBe1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ff794d-122c-4c30-85e4-2e888ecf4530"
      },
      "source": [
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\r\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\r\n",
        "                    validation_data=(X_valid_scaled, y_valid),\r\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 1.0979 - accuracy: 0.7331 - val_loss: 0.9395 - val_accuracy: 0.6994\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.8030 - accuracy: 0.7674 - val_loss: 0.6111 - val_accuracy: 0.8294\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.6610 - accuracy: 0.8077 - val_loss: 0.7778 - val_accuracy: 0.7658\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.6482 - accuracy: 0.8182 - val_loss: 0.5523 - val_accuracy: 0.8358\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.5417 - accuracy: 0.8346 - val_loss: 0.5322 - val_accuracy: 0.8516\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.5190 - accuracy: 0.8504 - val_loss: 0.5443 - val_accuracy: 0.8674\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4439 - accuracy: 0.8687 - val_loss: 0.5361 - val_accuracy: 0.8344\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4183 - accuracy: 0.8737 - val_loss: 0.5145 - val_accuracy: 0.8530\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3916 - accuracy: 0.8796 - val_loss: 0.6011 - val_accuracy: 0.8602\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3673 - accuracy: 0.8884 - val_loss: 0.4976 - val_accuracy: 0.8790\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3307 - accuracy: 0.8968 - val_loss: 0.4745 - val_accuracy: 0.8756\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3218 - accuracy: 0.9003 - val_loss: 0.4963 - val_accuracy: 0.8694\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2879 - accuracy: 0.9092 - val_loss: 0.4629 - val_accuracy: 0.8792\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2622 - accuracy: 0.9138 - val_loss: 0.4542 - val_accuracy: 0.8776\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2525 - accuracy: 0.9172 - val_loss: 0.4396 - val_accuracy: 0.8850\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2277 - accuracy: 0.9255 - val_loss: 0.4460 - val_accuracy: 0.8870\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2055 - accuracy: 0.9329 - val_loss: 0.5007 - val_accuracy: 0.8828\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2031 - accuracy: 0.9327 - val_loss: 0.4845 - val_accuracy: 0.8862\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1815 - accuracy: 0.9426 - val_loss: 0.5233 - val_accuracy: 0.8918\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1690 - accuracy: 0.9452 - val_loss: 0.4976 - val_accuracy: 0.8850\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1550 - accuracy: 0.9502 - val_loss: 0.5202 - val_accuracy: 0.8874\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1505 - accuracy: 0.9512 - val_loss: 0.5287 - val_accuracy: 0.8944\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1331 - accuracy: 0.9593 - val_loss: 0.5678 - val_accuracy: 0.8868\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1244 - accuracy: 0.9614 - val_loss: 0.5783 - val_accuracy: 0.8890\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.1148 - accuracy: 0.9643 - val_loss: 0.5958 - val_accuracy: 0.8898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcm1jC1_Bvtp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6b9cefa7-d186-437a-d26a-c6b96bb99ecf"
      },
      "source": [
        "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\r\n",
        "plt.axis([0, n_epochs-1, 0, 0.011])\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.ylabel(\"Learning Rate\")\r\n",
        "plt.title(\"Exponential Scheduling\", fontsize=14)\r\n",
        "plt.grid(True)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIgMN9vEumh5"
      },
      "source": [
        "# Deep Learning on CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBjFsEn6uh4I"
      },
      "source": [
        "keras.backend.clear_session()\r\n",
        "tf.random.set_seed(42)\r\n",
        "np.random.seed(42)\r\n",
        "import os"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IDmdZtnvdCN"
      },
      "source": [
        "model = keras.models.Sequential()\r\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\r\n",
        "for _ in range(20):\r\n",
        "  model.add(keras.layers.Dense(100, \r\n",
        "                               activation=\"elu\",\r\n",
        "                               kernel_initializer=\"he_normal\"))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evLRFp6ZwA_y"
      },
      "source": [
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO8PxxEaxId7"
      },
      "source": [
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\r\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\r\n",
        "              optimizer=optimizer,\r\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGSmeWNzyFdI",
        "outputId": "1cc641ce-ff2a-4ad1-d515-f89331861b20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\r\n",
        "\r\n",
        "X_train = X_train_full[5000:]\r\n",
        "y_train = y_train_full[5000:]\r\n",
        "X_valid = X_train_full[:5000]\r\n",
        "y_valid = y_train_full[:5000]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPPKySsVyrWo"
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\r\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\r\n",
        "run_index = 1\r\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\r\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\r\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGGpHcKKz8dc",
        "outputId": "3106e7b7-914d-4979-c26e-1718adc96566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=100,\r\n",
        "          validation_data=(X_valid, y_valid),\r\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 23s 14ms/step - loss: 9.8803 - accuracy: 0.1323 - val_loss: 2.1512 - val_accuracy: 0.2278\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 2.0979 - accuracy: 0.2324 - val_loss: 2.0026 - val_accuracy: 0.2490\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.9602 - accuracy: 0.2819 - val_loss: 1.9251 - val_accuracy: 0.2912\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.8670 - accuracy: 0.3167 - val_loss: 1.8850 - val_accuracy: 0.3184\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.8039 - accuracy: 0.3459 - val_loss: 1.7782 - val_accuracy: 0.3392\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.7543 - accuracy: 0.3632 - val_loss: 1.7527 - val_accuracy: 0.3582\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.7117 - accuracy: 0.3805 - val_loss: 1.7397 - val_accuracy: 0.3586\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.6737 - accuracy: 0.3937 - val_loss: 1.6730 - val_accuracy: 0.3878\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.6453 - accuracy: 0.4076 - val_loss: 1.6641 - val_accuracy: 0.3884\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.6169 - accuracy: 0.4166 - val_loss: 1.6802 - val_accuracy: 0.3904\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.5974 - accuracy: 0.4242 - val_loss: 1.6668 - val_accuracy: 0.3930\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.5717 - accuracy: 0.4320 - val_loss: 1.6273 - val_accuracy: 0.4110\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.5510 - accuracy: 0.4423 - val_loss: 1.6187 - val_accuracy: 0.4170\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5227 - accuracy: 0.4520 - val_loss: 1.6035 - val_accuracy: 0.4274\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.5222 - accuracy: 0.4489 - val_loss: 1.5885 - val_accuracy: 0.4242\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.5017 - accuracy: 0.4590 - val_loss: 1.5574 - val_accuracy: 0.4424\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.4872 - accuracy: 0.4614 - val_loss: 1.5750 - val_accuracy: 0.4314\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4709 - accuracy: 0.4687 - val_loss: 1.5603 - val_accuracy: 0.4442\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4572 - accuracy: 0.4752 - val_loss: 1.5536 - val_accuracy: 0.4442\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4369 - accuracy: 0.4819 - val_loss: 1.5814 - val_accuracy: 0.4354\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.4384 - accuracy: 0.4819 - val_loss: 1.5564 - val_accuracy: 0.4412\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4261 - accuracy: 0.4856 - val_loss: 1.5542 - val_accuracy: 0.4426\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4022 - accuracy: 0.4949 - val_loss: 1.5693 - val_accuracy: 0.4454\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3900 - accuracy: 0.4961 - val_loss: 1.5401 - val_accuracy: 0.4486\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3877 - accuracy: 0.5004 - val_loss: 1.5100 - val_accuracy: 0.4590\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3593 - accuracy: 0.5103 - val_loss: 1.5492 - val_accuracy: 0.4516\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3648 - accuracy: 0.5102 - val_loss: 1.5137 - val_accuracy: 0.4626\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3505 - accuracy: 0.5127 - val_loss: 1.5196 - val_accuracy: 0.4538\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3448 - accuracy: 0.5135 - val_loss: 1.5123 - val_accuracy: 0.4576\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3412 - accuracy: 0.5180 - val_loss: 1.5797 - val_accuracy: 0.4504\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3464 - accuracy: 0.5135 - val_loss: 1.5967 - val_accuracy: 0.4512\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3146 - accuracy: 0.5248 - val_loss: 1.5031 - val_accuracy: 0.4760\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3102 - accuracy: 0.5278 - val_loss: 1.5009 - val_accuracy: 0.4708\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2912 - accuracy: 0.5374 - val_loss: 1.5757 - val_accuracy: 0.4628\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2914 - accuracy: 0.5327 - val_loss: 1.5330 - val_accuracy: 0.4646\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2830 - accuracy: 0.5380 - val_loss: 1.5234 - val_accuracy: 0.4694\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2749 - accuracy: 0.5432 - val_loss: 1.5319 - val_accuracy: 0.4634\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2538 - accuracy: 0.5485 - val_loss: 1.5206 - val_accuracy: 0.4696\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2578 - accuracy: 0.5480 - val_loss: 1.5156 - val_accuracy: 0.4656\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2466 - accuracy: 0.5537 - val_loss: 1.5494 - val_accuracy: 0.4604\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2381 - accuracy: 0.5580 - val_loss: 1.5193 - val_accuracy: 0.4720\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2323 - accuracy: 0.5608 - val_loss: 1.5372 - val_accuracy: 0.4730\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2314 - accuracy: 0.5557 - val_loss: 1.5226 - val_accuracy: 0.4704\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2217 - accuracy: 0.5623 - val_loss: 1.5490 - val_accuracy: 0.4704\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2125 - accuracy: 0.5624 - val_loss: 1.5416 - val_accuracy: 0.4708\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1896 - accuracy: 0.5731 - val_loss: 1.5233 - val_accuracy: 0.4738\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1993 - accuracy: 0.5682 - val_loss: 1.5268 - val_accuracy: 0.4788\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1914 - accuracy: 0.5729 - val_loss: 1.5565 - val_accuracy: 0.4618\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1874 - accuracy: 0.5703 - val_loss: 1.5341 - val_accuracy: 0.4814\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1716 - accuracy: 0.5826 - val_loss: 1.5557 - val_accuracy: 0.4674\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1658 - accuracy: 0.5801 - val_loss: 1.5459 - val_accuracy: 0.4708\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1633 - accuracy: 0.5829 - val_loss: 1.5834 - val_accuracy: 0.4618\n",
            "Epoch 53/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1441 - accuracy: 0.5889 - val_loss: 1.5982 - val_accuracy: 0.4542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0fa2a7c518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjFH2re70Ecf",
        "outputId": "b0abd894-43eb-4062-eadd-4cea4317249c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.models.load_model(\"my_cifar10_model.h5\")\r\n",
        "model.evaluate(X_valid, y_valid)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 3ms/step - loss: 1.5009 - accuracy: 0.4708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5009092092514038, 0.4708000123500824]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzOYjJcx5Ue7",
        "outputId": "85e5fb24-e978-4b56-f746-06b5c2d1d236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Model with Batch Normalization\r\n",
        "\r\n",
        "model = keras.models.Sequential()\r\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\r\n",
        "model.add(keras.layers.BatchNormalization())\r\n",
        "\r\n",
        "for _ in range(20):\r\n",
        "  model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\r\n",
        "  model.add(keras.layers.BatchNormalization())\r\n",
        "  model.add(keras.layers.Activation(\"elu\"))\r\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\r\n",
        "\r\n",
        "optimizer=keras.optimizers.SGD(learning_rate=5e-4)\r\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\r\n",
        "              optimizer=optimizer,\r\n",
        "              metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\r\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\r\n",
        "run_index = 1 # increment every time you train the model\r\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\r\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\r\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\r\n",
        "\r\n",
        "model.fit(X_train, y_train, epochs=100,\r\n",
        "          validation_data=(X_valid, y_valid),\r\n",
        "          callbacks=callbacks)\r\n",
        "\r\n",
        "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\r\n",
        "model.evaluate(X_valid, y_valid)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 24s 13ms/step - loss: 2.4808 - accuracy: 0.1542 - val_loss: 2.0323 - val_accuracy: 0.2758\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 2.0381 - accuracy: 0.2684 - val_loss: 1.8728 - val_accuracy: 0.3278\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.9293 - accuracy: 0.3097 - val_loss: 1.7987 - val_accuracy: 0.3596\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.8618 - accuracy: 0.3347 - val_loss: 1.7535 - val_accuracy: 0.3744\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.8101 - accuracy: 0.3512 - val_loss: 1.7207 - val_accuracy: 0.3850\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.7831 - accuracy: 0.3617 - val_loss: 1.6958 - val_accuracy: 0.3938\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.7668 - accuracy: 0.3662 - val_loss: 1.6733 - val_accuracy: 0.4016\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.7369 - accuracy: 0.3813 - val_loss: 1.6561 - val_accuracy: 0.4038\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.7313 - accuracy: 0.3819 - val_loss: 1.6405 - val_accuracy: 0.4084\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.7035 - accuracy: 0.3929 - val_loss: 1.6264 - val_accuracy: 0.4172\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6920 - accuracy: 0.3967 - val_loss: 1.6131 - val_accuracy: 0.4212\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6803 - accuracy: 0.4022 - val_loss: 1.5980 - val_accuracy: 0.4250\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.6609 - accuracy: 0.4084 - val_loss: 1.5929 - val_accuracy: 0.4262\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6468 - accuracy: 0.4142 - val_loss: 1.5838 - val_accuracy: 0.4322\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6419 - accuracy: 0.4137 - val_loss: 1.5742 - val_accuracy: 0.4316\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6374 - accuracy: 0.4138 - val_loss: 1.5690 - val_accuracy: 0.4372\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6210 - accuracy: 0.4233 - val_loss: 1.5616 - val_accuracy: 0.4384\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6120 - accuracy: 0.4227 - val_loss: 1.5543 - val_accuracy: 0.4428\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6070 - accuracy: 0.4297 - val_loss: 1.5484 - val_accuracy: 0.4442\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5916 - accuracy: 0.4329 - val_loss: 1.5455 - val_accuracy: 0.4476\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5813 - accuracy: 0.4352 - val_loss: 1.5396 - val_accuracy: 0.4508\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5754 - accuracy: 0.4396 - val_loss: 1.5324 - val_accuracy: 0.4500\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5665 - accuracy: 0.4410 - val_loss: 1.5293 - val_accuracy: 0.4526\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5556 - accuracy: 0.4449 - val_loss: 1.5251 - val_accuracy: 0.4592\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5587 - accuracy: 0.4465 - val_loss: 1.5213 - val_accuracy: 0.4586\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5372 - accuracy: 0.4546 - val_loss: 1.5146 - val_accuracy: 0.4602\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5464 - accuracy: 0.4504 - val_loss: 1.5108 - val_accuracy: 0.4620\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5299 - accuracy: 0.4576 - val_loss: 1.5087 - val_accuracy: 0.4628\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5369 - accuracy: 0.4533 - val_loss: 1.5036 - val_accuracy: 0.4632\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5309 - accuracy: 0.4540 - val_loss: 1.5021 - val_accuracy: 0.4616\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5193 - accuracy: 0.4577 - val_loss: 1.4980 - val_accuracy: 0.4640\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.5015 - accuracy: 0.4624 - val_loss: 1.4967 - val_accuracy: 0.4654\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5094 - accuracy: 0.4592 - val_loss: 1.4897 - val_accuracy: 0.4698\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4955 - accuracy: 0.4686 - val_loss: 1.4949 - val_accuracy: 0.4640\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5001 - accuracy: 0.4631 - val_loss: 1.4860 - val_accuracy: 0.4672\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4923 - accuracy: 0.4679 - val_loss: 1.4845 - val_accuracy: 0.4694\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4823 - accuracy: 0.4740 - val_loss: 1.4833 - val_accuracy: 0.4690\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4740 - accuracy: 0.4729 - val_loss: 1.4839 - val_accuracy: 0.4716\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4707 - accuracy: 0.4748 - val_loss: 1.4791 - val_accuracy: 0.4722\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4674 - accuracy: 0.4772 - val_loss: 1.4742 - val_accuracy: 0.4734\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4599 - accuracy: 0.4811 - val_loss: 1.4724 - val_accuracy: 0.4766\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4636 - accuracy: 0.4776 - val_loss: 1.4702 - val_accuracy: 0.4756\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4629 - accuracy: 0.4783 - val_loss: 1.4635 - val_accuracy: 0.4786\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4590 - accuracy: 0.4786 - val_loss: 1.4658 - val_accuracy: 0.4810\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4467 - accuracy: 0.4873 - val_loss: 1.4613 - val_accuracy: 0.4762\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4362 - accuracy: 0.4906 - val_loss: 1.4646 - val_accuracy: 0.4812\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.4380 - accuracy: 0.4864 - val_loss: 1.4551 - val_accuracy: 0.4812\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 1.4331 - accuracy: 0.4913 - val_loss: 1.4576 - val_accuracy: 0.4810\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4327 - accuracy: 0.4886 - val_loss: 1.4505 - val_accuracy: 0.4828\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4154 - accuracy: 0.4978 - val_loss: 1.4541 - val_accuracy: 0.4770\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4247 - accuracy: 0.4902 - val_loss: 1.4484 - val_accuracy: 0.4872\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4173 - accuracy: 0.4959 - val_loss: 1.4462 - val_accuracy: 0.4864\n",
            "Epoch 53/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4103 - accuracy: 0.4977 - val_loss: 1.4505 - val_accuracy: 0.4810\n",
            "Epoch 54/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.3986 - accuracy: 0.5028 - val_loss: 1.4491 - val_accuracy: 0.4822\n",
            "Epoch 55/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4092 - accuracy: 0.5012 - val_loss: 1.4430 - val_accuracy: 0.4854\n",
            "Epoch 56/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3919 - accuracy: 0.5039 - val_loss: 1.4425 - val_accuracy: 0.4854\n",
            "Epoch 57/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3943 - accuracy: 0.5068 - val_loss: 1.4491 - val_accuracy: 0.4850\n",
            "Epoch 58/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3966 - accuracy: 0.5006 - val_loss: 1.4430 - val_accuracy: 0.4894\n",
            "Epoch 59/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3809 - accuracy: 0.5098 - val_loss: 1.4400 - val_accuracy: 0.4902\n",
            "Epoch 60/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3870 - accuracy: 0.5057 - val_loss: 1.4389 - val_accuracy: 0.4902\n",
            "Epoch 61/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.3737 - accuracy: 0.5102 - val_loss: 1.4388 - val_accuracy: 0.4894\n",
            "Epoch 62/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3755 - accuracy: 0.5105 - val_loss: 1.4336 - val_accuracy: 0.4940\n",
            "Epoch 63/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3740 - accuracy: 0.5151 - val_loss: 1.4368 - val_accuracy: 0.4932\n",
            "Epoch 64/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3725 - accuracy: 0.5134 - val_loss: 1.4334 - val_accuracy: 0.4926\n",
            "Epoch 65/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3594 - accuracy: 0.5191 - val_loss: 1.4336 - val_accuracy: 0.4948\n",
            "Epoch 66/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3609 - accuracy: 0.5158 - val_loss: 1.4337 - val_accuracy: 0.4904\n",
            "Epoch 67/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3551 - accuracy: 0.5141 - val_loss: 1.4296 - val_accuracy: 0.4980\n",
            "Epoch 68/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3468 - accuracy: 0.5223 - val_loss: 1.4287 - val_accuracy: 0.4930\n",
            "Epoch 69/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3510 - accuracy: 0.5190 - val_loss: 1.4272 - val_accuracy: 0.4964\n",
            "Epoch 70/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3528 - accuracy: 0.5180 - val_loss: 1.4236 - val_accuracy: 0.4942\n",
            "Epoch 71/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.3449 - accuracy: 0.5213 - val_loss: 1.4340 - val_accuracy: 0.4892\n",
            "Epoch 72/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.3378 - accuracy: 0.5218 - val_loss: 1.4293 - val_accuracy: 0.5004\n",
            "Epoch 73/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3457 - accuracy: 0.5228 - val_loss: 1.4302 - val_accuracy: 0.4966\n",
            "Epoch 74/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3311 - accuracy: 0.5285 - val_loss: 1.4270 - val_accuracy: 0.4998\n",
            "Epoch 75/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3187 - accuracy: 0.5326 - val_loss: 1.4302 - val_accuracy: 0.4954\n",
            "Epoch 76/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3174 - accuracy: 0.5295 - val_loss: 1.4289 - val_accuracy: 0.5020\n",
            "Epoch 77/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.3251 - accuracy: 0.5284 - val_loss: 1.4215 - val_accuracy: 0.4974\n",
            "Epoch 78/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3135 - accuracy: 0.5327 - val_loss: 1.4281 - val_accuracy: 0.5032\n",
            "Epoch 79/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3132 - accuracy: 0.5316 - val_loss: 1.4270 - val_accuracy: 0.5074\n",
            "Epoch 80/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3127 - accuracy: 0.5326 - val_loss: 1.4225 - val_accuracy: 0.4980\n",
            "Epoch 81/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3135 - accuracy: 0.5308 - val_loss: 1.4182 - val_accuracy: 0.5028\n",
            "Epoch 82/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3057 - accuracy: 0.5326 - val_loss: 1.4334 - val_accuracy: 0.4972\n",
            "Epoch 83/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2979 - accuracy: 0.5366 - val_loss: 1.4392 - val_accuracy: 0.5002\n",
            "Epoch 84/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3084 - accuracy: 0.5358 - val_loss: 1.4224 - val_accuracy: 0.4990\n",
            "Epoch 85/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3084 - accuracy: 0.5356 - val_loss: 1.4224 - val_accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2925 - accuracy: 0.5384 - val_loss: 1.4220 - val_accuracy: 0.5016\n",
            "Epoch 87/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2808 - accuracy: 0.5431 - val_loss: 1.4285 - val_accuracy: 0.4950\n",
            "Epoch 88/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2898 - accuracy: 0.5403 - val_loss: 1.4349 - val_accuracy: 0.4942\n",
            "Epoch 89/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2857 - accuracy: 0.5421 - val_loss: 1.4250 - val_accuracy: 0.5016\n",
            "Epoch 90/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2774 - accuracy: 0.5449 - val_loss: 1.4479 - val_accuracy: 0.4922\n",
            "Epoch 91/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2806 - accuracy: 0.5459 - val_loss: 1.4254 - val_accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2851 - accuracy: 0.5385 - val_loss: 1.4246 - val_accuracy: 0.5032\n",
            "Epoch 93/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2732 - accuracy: 0.5483 - val_loss: 1.4324 - val_accuracy: 0.4996\n",
            "Epoch 94/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2701 - accuracy: 0.5478 - val_loss: 1.4233 - val_accuracy: 0.5064\n",
            "Epoch 95/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2702 - accuracy: 0.5485 - val_loss: 1.4220 - val_accuracy: 0.5028\n",
            "Epoch 96/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2621 - accuracy: 0.5479 - val_loss: 1.4205 - val_accuracy: 0.5056\n",
            "Epoch 97/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2675 - accuracy: 0.5435 - val_loss: 1.4207 - val_accuracy: 0.5006\n",
            "Epoch 98/100\n",
            "1407/1407 [==============================] - 18s 12ms/step - loss: 1.2713 - accuracy: 0.5470 - val_loss: 1.4217 - val_accuracy: 0.5054\n",
            "Epoch 99/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2550 - accuracy: 0.5525 - val_loss: 1.4186 - val_accuracy: 0.5048\n",
            "Epoch 100/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2548 - accuracy: 0.5512 - val_loss: 1.4224 - val_accuracy: 0.5054\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4182 - accuracy: 0.5028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4181780815124512, 0.5027999877929688]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIEr5yqU7IGn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}